![](https://habrastorage.org/webt/lo/lw/cs/lolwcsuyedsd3yx3kgfc18ve3_y.png)

# Kaggle Dataset
~ The same as a [Kaggle Dataset](https://www.kaggle.com/kashnitsky/cs231n-by-stanford). Convenient to have multiple GPUs running in parallel. Transition to 2019 versions of assignments is in progress.

# Assignment 1
 - [k-Nearest Neighbor (kNN) exercise](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment1/knn_solution_yorko.ipynb) + [comments on some derivations](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment1/knn_comments_yorko.ipynb)
 - [Softmax classifier](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment1/softmax_solution_yorko.ipynb)
 - [Multi-class SVM](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment1/svm_solution_yorko.ipynb)
 - [Two-layer net](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment1/two_layer_net_solution_yorko.ipynb)
 - [More features](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment1/features_solution_yorko.ipynb)

# Assignment 2
 - [Fully-Connected Neural Nets](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment2/FullyConnectedNets_solution_yorko.ipynb)
 - [Batch Normalization](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment2/BatchNormalization_solution_yorko.ipynb	)
 - [Dropout](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment2/Dropout_solution_yorko.ipynb)
 - [Convolutional Networks](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment2/ConvolutionalNetworks_solution_yorko.ipynb)
 - [PyTorch convnet](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment2/PyTorch_solution_yorko.ipynb)

# Assignment 3
- [Image captioning with RNNs](https://nbviewer.jupyter.org/github/Yorko/stanford_cs231n_2018/blob/master/assignment3/RNN_Captioning_solution_yorko.ipynb?flush_cache=true)
- [Image captioning with LSTMs](http://nbviewer.ipython.org/urls/raw.github.com/Yorko/stanford_cs231n_2018/master/assignment3/LSTM_Captioning_solution_yorko.ipynb)
- to be continued...

## Passing cs231n together within the [OpenDataScience](http://ods.ai) community
Next start - from **29.04.2019** till **30.06.2019**

**Main links**
- The [course](http://cs231n.stanford.edu/) itself 
- Video-lectures, youtube [channel](https://goo.gl/pcj7c8). Prerequisites are given in the 1st lecture  
- [Syllabus](http://cs231n.stanford.edu/syllabus.html) with assignments

**Assignments**

There are 3 big and tough assignments in this course. We’ll have deadlines and exemplar solutions (by me or smb else) to be discussed.

**Competitions & projects**

In the original course they've got [projects](http://cs231n.stanford.edu/project.html).
You can also complete one, but actually, lectures and assignments is already a good workload.
To do smth more, I propose 3 variants:
- a personal pet-project (will be nice to show in your portfolio) [here](https://digits-draw-recognize.herokuapp.com/) is an example by @artgor and a [description](https://habrahabr.ru/company/ods/blog/335998/) in :ru: (you can translate it, but the app is self-explanatory)
- a Kaggle competition. Maybe a playground one, to start with. This one, persay: ["Dog Breed Identification"](https://www.kaggle.com/c/dog-breed-identification) 
- you can also write a tutorial

**GPUs**

Authors claim that you can pass the course even with typical hardware. However, I recommend to rent a machine with GPU. The most convenient option right now is either Google Colaboratory ([tutorial](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d) on Medium) or even Kaggle Kernels (just switch on GPU in Kernel settings).

**Plan**

- 29.04.19 – 05.05.19. [Lecture 1](https://www.youtube.com/watch?v=vT1JzLTH4G4&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv) and [Lecture 2](https://www.youtube.com/watch?v=OoUX-nOEjG0&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=2)
- 06.05.19 – 12.05.19. [Lecture 3](https://www.youtube.com/watch?v=h7iBpEHGVNc&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=3) and [Lecture 4](https://www.youtube.com/watch?v=h7iBpEHGVNc&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=4)
- 13.05.19 – 19.05.19. [Lecture 5](https://www.youtube.com/watch?v=bNb2fEVKeEo&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=5) and [Lecture 6](https://www.youtube.com/watch?v=wEoyxE0GP2M&index=6&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
- 19.05.19 – **A1 due**. You can discuss it in the **#class_cs231n** channel in Slack
- 20.05.19 – 26.05.19. [Lecture 7](https://www.youtube.com/watch?v=_JB0AO7QxSA&index=7&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv) and [Lecture 8](https://www.youtube.com/watch?v=6SlgtELqOWc&index=8&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv)
- 27.05.19 – 02.06.19. [Lecture 9](https://www.youtube.com/watch?v=DAOcjicFr1Y&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=9) and [Lecture 10](https://www.youtube.com/watch?v=6niqTuYFZLQ&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=10)
- 03.06.19 – 09.06.19. [Lecture 11](https://www.youtube.com/watch?v=nDPWywWRIRo&index=11&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv) and [Lecture 12](https://www.youtube.com/watch?v=6wcs6szJWMY&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=12)
- 09.06.19 – **A2 due**. You can discuss it in the **#class_cs231n** channel in Slack
- 10.06.19 – 16.06.19. [Lecture 13](https://www.youtube.com/watch?v=5WoItGTWV54&index=13&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv) and [Lecture 14](https://www.youtube.com/watch?v=lvoHnicueoE&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=14)
- 17.06.19 – 23.06.19. [Lecture 15](https://www.youtube.com/watch?v=eZdOkDtYMoo) and [Lecture 16](https://www.youtube.com/watch?v=CIfsB_EYsVI&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=16)
- 30.06.19 – **A3 due**. You can discuss it in the **#class_cs231n** channel in Slack
